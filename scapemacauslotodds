#!/usr/bin/env python3
"""
Market Data Collector (all matches)
- Runs headless by default (no prompt)
- Clicks each market tab once
- Does NOT click match rows
- For each market, picks the correct match block by home/away text
- Count mismatches produce warnings (kept); only event/team mismatch is fatal
"""

import asyncio
import json
import csv
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
from playwright.async_api import async_playwright


class AllMarketsCollector:
    def __init__(self):
        self.headless = True
        self.output_dir = Path("all_markets_analysis")
        self.output_dir.mkdir(exist_ok=True)

        # Whitelist of markets (exact text)
        self.allowed_markets = {
            "å…¨å ´ä¸‰åˆä¸€è³ çŽ‡",
            "ä¸ŠåŠå ´ä¸‰åˆä¸€è³ çŽ‡",
            "ä¸ŠåŠå ´è§’çƒæ•¸è³ çŽ‡",
            "ä¸ŠåŠå ´æ³¢è†½",
            "ä¸ŠåŠå ´æ³¢è†½çµ„åˆ",
            "ä¸ŠåŠå ´å…¥çƒå–®/é›™æ•¸",
            "ä¸ŠåŠå ´çƒéšŠå…¥çƒæ•¸",
            "è§’çƒæ•¸è³ çŽ‡",
            "æ³¢è†½",
            "æ³¢è†½çµ„åˆ",
            "ä¸ŠåŠå ´/å…¨å ´è³½æžœ",
            "å…¥çƒå–®/é›™æ•¸",
            "å…¨å ´å…¥çƒç¸½æ•¸",
            "ä¸Š/ä¸‹åŠå ´å…¥çƒè¼ƒå¤š",
            "çƒéšŠå…¥çƒæ•¸",
            "æœ€å…ˆå…¥çƒçƒéšŠ",
            "é¦–åå…¥çƒçƒå“¡",
        }

        # Expected counts (for warnings only)
        self.expected_counts = {
            "å…¨å ´ä¸‰åˆä¸€è³ çŽ‡": 19,  # adjust if you observe a different stable count
            "ä¸ŠåŠå ´ä¸‰åˆä¸€è³ çŽ‡": 7,
            "ä¸ŠåŠå ´è§’çƒæ•¸è³ çŽ‡": 7,
            "ä¸ŠåŠå ´æ³¢è†½": 26,
            "ä¸ŠåŠå ´æ³¢è†½çµ„åˆ": 6,
            "ä¸ŠåŠå ´å…¥çƒå–®/é›™æ•¸": 2,
            "ä¸ŠåŠå ´çƒéšŠå…¥çƒæ•¸": 12,
            "è§’çƒæ•¸è³ çŽ‡": 7,
            "æ³¢è†½": 26,
            "æ³¢è†½çµ„åˆ": 6,
            "ä¸ŠåŠå ´/å…¨å ´è³½æžœ": 9,
            "å…¥çƒå–®/é›™æ•¸": 2,
            "å…¨å ´å…¥çƒç¸½æ•¸": 4,
            "ä¸Š/ä¸‹åŠå ´å…¥çƒè¼ƒå¤š": 3,
            "çƒéšŠå…¥çƒæ•¸": 12,
            "æœ€å…ˆå…¥çƒçƒéšŠ": 3,
            "é¦–åå…¥çƒçƒå“¡": 23,
        }

    async def collect_all(self):
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=self.headless, slow_mo=200)
            context = await browser.new_context(
                viewport={"width": 1600, "height": 900},
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            )
            page = await context.new_page()

            try:
                print("ðŸŒ Loading Macau Slot website...")
                await page.goto(
                    "https://www.macau-slot.com/content/soccer/coming_bet.html",
                    timeout=30000,
                    wait_until="networkidle"
                )
                await asyncio.sleep(3)

                # Collect market tabs once (assumed common for all matches)
                market_buttons = await page.query_selector_all("li.msl-cm-methods")
                market_names = []
                for btn in market_buttons:
                    try:
                        text = await btn.text_content()
                        if text and text.strip():
                            market_names.append(text.strip())
                    except:
                        continue
                print("ðŸ”Ž Market tabs found:", [repr(m) for m in market_names])
                print(f"âœ… Found {len(market_names)} markets (before whitelist)")

                # Grab all match elements
                matches = await page.query_selector_all(".msl-ls-item")
                if not matches:
                    print("âŒ No matches found!")
                    return

                all_events_data = {}

                for match_idx, match_el in enumerate(matches):
                    # Identify target teams and event_id
                    home_team, away_team, event_id = await self._extract_match_header(match_el)
                    print(f"\nðŸŽ¯ Match {match_idx+1}: Event {event_id} | Home={home_team} | Away={away_team}")

                    event_data = {}
                    # Iterate markets
                    for i, market_name in enumerate(market_names):
                        if market_name not in self.allowed_markets:
                            print(f"[skip] {repr(market_name)} not in whitelist")
                            continue
                        print(f"[{i + 1:2}/{len(market_names)}] {market_name}")
                        try:
                            await self._click_market_button(page, market_name)
                            await asyncio.sleep(2.5)
                            mdata = await self._capture_market_data(
                                page=page,
                                market_name=market_name,
                                index=i,
                                expected_home=home_team,
                                expected_away=away_team,
                                expected_event_id=event_id
                            )
                            if "error" in mdata:
                                print(f"   âš ï¸ {mdata['error']}")
                            else:
                                if mdata.get("warnings"):
                                    print(f"   âš ï¸ warnings: {mdata['warnings']}")
                                print(f"   âœ… {mdata['numbers_count']} numbers")
                            event_data[market_name] = mdata
                            await self._take_market_screenshot(page, market_name, i, event_id, match_idx)
                        except Exception as e:
                            print(f"   âŒ Error with {market_name}: {e}")
                            event_data[market_name] = {"error": str(e), "market_name": market_name}

                    all_events_data[event_id] = {
                        "event_id": event_id,
                        "home_team": home_team,
                        "away_team": away_team,
                        "markets": event_data
                    }

                # Save all events
                await self._save_all_events(all_events_data)

            finally:
                await browser.close()

    async def _extract_match_header(self, match_el):
        text = (await match_el.text_content() or "")
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        event_id = await match_el.get_attribute("data-ev-id") or "unknown"
        home, away = "Unknown", "Unknown"
        for i, line in enumerate(lines):
            if line == '|' and i > 0 and i + 1 < len(lines):
                home = lines[i - 1]
                away = lines[i + 1]
                break
            elif "|" in line and i > 0:
                parts = line.split("|")
                if len(parts) == 2:
                    home = parts[0].strip()
                    away = parts[1].strip()
                    break
        return home, away, event_id

    async def _click_market_button(self, page, market_name: str):
        try:
            await page.click(f"text={market_name}", timeout=3000)
            return
        except:
            buttons = await page.query_selector_all("li.msl-cm-methods")
            for btn in buttons:
                text = (await btn.text_content() or "").strip()
                if text == market_name:
                    await btn.click()
                    return
        raise RuntimeError(f"Market button not found for exact name: {market_name}")

    async def _pick_match_element(self, page, expected_home: str, expected_away: str):
        matches = await page.query_selector_all(".msl-ls-item")
        for m in matches:
            text = (await m.text_content() or "")
            if expected_home in text and expected_away in text:
                return m
        return None

    async def _capture_match_data(self, page, market_name: str, expected_home: str, expected_away: str, expected_event_id: str) -> Dict:
        match = await self._pick_match_element(page, expected_home, expected_away)
        if not match:
            return {
                "event_id": expected_event_id,
                "market_name": market_name,
                "home_team": expected_home,
                "away_team": expected_away,
                "match_time": "Unknown",
                "total_lines": 0,
                "all_lines": [],
                "numbers_count": 0,
                "all_numbers": [],
                "html_sample": "",
                "timestamp": datetime.now().isoformat(),
                "warnings": ["Target match element not found; using stub"]
            }

        actual_event_id = await match.get_attribute("data-ev-id") or expected_event_id or "unknown"
        all_text = await match.text_content()
        lines = [l.strip() for l in all_text.split('\n') if l.strip()]
        all_numbers = self._extract_all_numbers(lines)
        html_content = await match.inner_html()
        home_team, away_team = self._extract_teams(lines)
        if home_team == "Unknown":
            home_team = expected_home
        if away_team == "Unknown":
            away_team = expected_away
        if actual_event_id == "unknown" and expected_event_id:
            actual_event_id = expected_event_id
        match_time = self._extract_match_time(lines)

        return {
            "event_id": actual_event_id,
            "market_name": market_name,
            "home_team": home_team,
            "away_team": away_team,
            "match_time": match_time,
            "total_lines": len(lines),
            "all_lines": lines,
            "numbers_count": len(all_numbers),
            "all_numbers": all_numbers,
            "html_sample": html_content[:1000],
            "timestamp": datetime.now().isoformat()
        }

    def _validate_event(self, data: Dict, expected_event_id: str, expected_home: str, expected_away: str) -> List[str]:
        errors = []
        if expected_event_id and data.get("event_id") != expected_event_id:
            errors.append(f"Event ID mismatch. Expected {expected_event_id}, got {data.get('event_id')}")
        if data.get("home_team") != expected_home:
            errors.append(f"Home team mismatch. Expected {expected_home}, got {data.get('home_team')}")
        if data.get("away_team") != expected_away:
            errors.append(f"Away team mismatch. Expected {expected_away}, got {data.get('away_team')}")
        return errors

    def _validate_market_content(self, market_name: str, data: Dict) -> Optional[str]:
        expected = self.expected_counts.get(market_name)
        actual = data.get("numbers_count", 0)
        if expected is not None and expected != actual:
            return f"warn: Numbers count mismatch for {market_name}. Expected {expected}, got {actual}"
        return None

    async def _capture_market_data(self, page, market_name: str, index: int,
                                   expected_home: str, expected_away: str, expected_event_id: str) -> Dict:
        basic = await self._capture_match_data(page, market_name, expected_home, expected_away, expected_event_id)

        # fill targets if unknown and event matches
        if basic.get("event_id") == expected_event_id:
            if basic.get("home_team") == "Unknown":
                basic["home_team"] = expected_home
            if basic.get("away_team") == "Unknown":
                basic["away_team"] = expected_away

        evt_errors = self._validate_event(basic, expected_event_id, expected_home, expected_away)
        if evt_errors:
            return {**basic, "market_index": index, "error": "; ".join(evt_errors)}

        shape_warning = self._validate_market_content(market_name, basic)
        if shape_warning:
            basic.setdefault("warnings", []).append(shape_warning)

        match = await self._pick_match_element(page, expected_home, expected_away)
        all_elements = await match.query_selector_all("*") if match else []
        element_counts = {}
        for elem in all_elements[:200]:
            tag = await elem.evaluate("el => el.tagName")
            element_counts[tag] = element_counts.get(tag, 0) + 1

        structures_found = {
            "tables": len(await match.query_selector_all("table")) if match else 0,
            "grids": len(await match.query_selector_all("div[class*='grid']")) if match else 0,
            "rows": len(await match.query_selector_all("tr, div[class*='row']")) if match else 0,
            "odds_cells": len(await match.query_selector_all("div[class*='odds'], td[class*='odds']")) if match else 0,
            "input_fields": len(await match.query_selector_all("input, select, textarea")) if match else 0
        }

        visible_text = await match.text_content() if match else ""
        paragraphs = [p.strip() for p in visible_text.split('\n\n') if p.strip()] if visible_text else []

        return {
            **basic,
            "market_index": index,
            "element_counts": element_counts,
            "structures_found": structures_found,
            "paragraphs_count": len(paragraphs),
            "paragraphs_sample": paragraphs[:5],
            "market_analysis": self._analyze_market_pattern(market_name, basic.get("all_numbers", []))
        }

    async def _take_market_screenshot(self, page, market_name: str, index: int, event_id: str, match_idx: int):
        clean_name = market_name.replace('/', '_').replace(' ', '_').replace('|', '_')
        filename = f"{event_id}_m{match_idx+1}_{index + 1:02}_{clean_name}.png"
        filepath = self.output_dir / "screenshots" / filename
        filepath.parent.mkdir(exist_ok=True, parents=True)
        try:
            match = await self._pick_match_element(page, expected_home=None, expected_away=None)
            # fallback to first match for screenshot if selection fails
            if match:
                await match.screenshot(path=str(filepath))
        except:
            await page.screenshot(path=str(filepath))

    def _extract_all_numbers(self, lines: List[str]) -> List[float]:
        nums = []
        for line in lines:
            for part in line.split():
                clean = part.replace(',', '').replace('â€”', '-').strip()
                if self._is_number(clean):
                    try:
                        nums.append(float(clean))
                    except:
                        continue
        return nums

    def _is_number(self, text: str) -> bool:
        if not text:
            return False
        if text.startswith('-'):
            text = text[1:]
        return text.replace('.', '', 1).isdigit()

    def _extract_teams(self, lines: List[str]) -> tuple:
        home, away = "Unknown", "Unknown"
        for i, line in enumerate(lines):
            if line == '|' and i > 0 and i + 1 < len(lines):
                home = lines[i - 1]
                away = lines[i + 1]
                break
            elif "|" in line and i > 0:
                parts = line.split("|")
                if len(parts) == 2:
                    home = parts[0].strip()
                    away = parts[1].strip()
                    break
        return home, away

    def _extract_match_time(self, lines: List[str]) -> str:
        for line in lines:
            if ':' in line and len(line) == 5:
                try:
                    h, m = map(int, line.split(':'))
                    if 0 <= h < 24 and 0 <= m < 60:
                        return line
                except:
                    continue
        return "Unknown"

    def _analyze_market_pattern(self, market_name: str, numbers: List[float]) -> Dict:
        n = len(numbers)
        if "æ³¢è†½" in market_name and n == 26:
            p, d = "CORRECT_SCORE_26", "10 pairs (home/away) + 6 home-only"
        elif n == 3:
            p, d = "THREE_WAY", "Likely 1X2"
        elif n == 2:
            p, d = "BINARY", "Two-way market"
        elif n == 1:
            p, d = "SINGLE", "Single number"
        elif n > 20:
            p, d = "GRID_COMPLEX", f"Complex grid with {n} numbers"
        elif 4 <= n <= 10 and n % 2 == 0:
            p, d = "HANDICAP_PAIRS", f"Asian handicap with {n//2} lines"
        else:
            p, d = "UNKNOWN", f"Unknown pattern with {n} numbers"
        stats = {}
        if numbers:
            stats = {
                "min": min(numbers),
                "max": max(numbers),
                "avg": sum(numbers)/n,
                "has_decimals": any(x != int(x) for x in numbers),
                "range": max(numbers) - min(numbers)
            }
        return {"pattern_type": p, "description": d, "number_count": n, "stats": stats}

    async def _save_all_events(self, all_events_data: Dict):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Drop only markets with errors; keep warnings
        cleaned_events = {}
        for eid, payload in all_events_data.items():
            markets = payload.get("markets", {})
            cleaned_markets = {}
            for mname, data in markets.items():
                if "error" in data:
                    print(f"â­ï¸ Skipping {mname} for event {eid} due to error: {data['error']}")
                    continue
                cleaned_markets[mname] = data
            cleaned_events[eid] = {
                "event_id": payload.get("event_id"),
                "home_team": payload.get("home_team"),
                "away_team": payload.get("away_team"),
                "markets": cleaned_markets
            }

        complete_data = {
            "scrape_time": datetime.now().isoformat(),
            "total_events": len(cleaned_events),
            "events": cleaned_events
        }
        jf = self.output_dir / f"complete_market_data_multi_{ts}.json"
        jf.write_text(json.dumps(complete_data, indent=2, ensure_ascii=False), encoding="utf-8")
        print(f"ðŸ“ Complete data: {jf.name}")

        cf = self.output_dir / f"market_summary_multi_{ts}.csv"
        with open(cf, 'w', newline='', encoding='utf-8') as f:
            w = csv.writer(f)
            w.writerow(["Event ID","Home","Away","Market Name","Market Index","Numbers Count","Pattern Type","Lines","Warnings"])
            for eid, payload in cleaned_events.items():
                for mname, data in payload["markets"].items():
                    w.writerow([
                        eid,
                        payload.get("home_team",""),
                        payload.get("away_team",""),
                        mname,
                        data.get("market_index",""),
                        data.get("numbers_count",0),
                        data.get("market_analysis",{}).get("pattern_type",""),
                        data.get("total_lines",0),
                        "; ".join(data.get("warnings", [])) if data.get("warnings") else ""
                    ])
        print(f"ðŸ“Š Summary CSV: {cf.name}")

        raw_dir = self.output_dir / "raw_lines"
        raw_dir.mkdir(exist_ok=True)
        for eid, payload in cleaned_events.items():
            for mname, data in payload["markets"].items():
                if "all_lines" in data:
                    clean_name = mname.replace('/', '_').replace(' ', '_')
                    rf = raw_dir / f"{eid}_{clean_name}.txt"
                    with open(rf, 'w', encoding='utf-8') as f:
                        f.write(f"Event ID: {eid}\n")
                        f.write(f"Home: {payload.get('home_team','')}\n")
                        f.write(f"Away: {payload.get('away_team','')}\n")
                        f.write(f"Market: {mname}\n")
                        f.write(f"Numbers found: {len(data.get('all_numbers', []))}\n")
                        if data.get("warnings"):
                            f.write(f"Warnings: {'; '.join(data['warnings'])}\n")
                        f.write("="*50 + "\n\n")
                        for i, line in enumerate(data["all_lines"]):
                            f.write(f"{i:3}: {line}\n")
        print(f"ðŸ“ Raw lines saved in: {raw_dir.name}")


async def main():
    print("="*60)
    print("ALL MARKETS DATA COLLECTOR (All Matches, Headless)")
    print("="*60)
    collector = AllMarketsCollector()
    await collector.collect_all()


if __name__ == "__main__":
    asyncio.run(main())
